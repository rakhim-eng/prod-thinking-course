<script src="./gtm.html"></script>
<script src="/lessons/gtm.html"></script>
# Инженерное мышление в продакшене

## Урок 5: Когда логов много, а понимания ноль

Полчаса прошло с начала инцидента. Ты открыл все логи. Kibana показывает миллион строк. Slack заполнен сообщениями от команды. Метрики продолжают гореть. А ты всё ещё не понимаешь, где собака зарыта. Классическая ситуация для сложных проблем.

Первая ошибка пытаться читать всё подряд. Логи нужно фильтровать с самого начала. Начни с ключевых моментов. Первый алерт показал ошибку в каком сервисе. Иди к тем логам. Найди первые случаи ошибки. Посмотри что было за пять секунд до.

Второй шаг группировка. Раздели логи по типам ошибок. Сколько ERROR с таймаутами. Сколько с DB connection refused. Сколько с внешними API. Паттерн покажет где копать дальше.

Третий корреляция с метриками. Не смотри логи в вакууме. Сравни всплеск ошибок с графиками CPU, памяти, сетевого трафика. Время первого лога совпадает с пиком нагрузки. Или падением соединений к базе.

Четвёртый поиск аномалий. Сравни текущие логи с нормальными. Что появилось нового. Строка про "connection pool exhausted". Или "rate limit exceeded" от внешнего сервиса. Эти маркеры ведут к корню.

Пятый временная последовательность. Построй timeline. В какое время первый алерт. Через сколько метрики начали падать. Когда появился новый тип ошибки. Последовательность покажет причинно следственную связь.

Шестой гипотезы и тесты. Сформулируй две три возможные причины. Проверь каждую по логам. Гипотеза про DB провалилась. Переключись на сеть.

Такой подход превращает хаос логов в управляемый процесс. За час понимаешь больше, чем за смену слепого чтения. Главное начинать с фильтрации, а не тонуть в потоке.
